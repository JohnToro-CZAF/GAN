{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import itertools\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "num_epochs = 200\n",
    "decay_epoch = 100\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "size = 256  # Image size\n",
    "input_nc = 3  # Number of input image channels\n",
    "output_nc = 3  # Number of output image channels\n",
    "ngf = 64  # Number of generator filters in first conv layer\n",
    "ndf = 64  # Number of discriminator filters in first conv layer\n",
    "lambda_cyc = 10  # Cycle consistency loss weight\n",
    "lambda_id = 0.5 * lambda_cyc  # Identity loss weight\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#        NETWORKS            #\n",
    "##############################\n",
    "\n",
    "# Define the Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3),\n",
    "            nn.InstanceNorm2d(dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "# Define the Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initial convolution block\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7),\n",
    "            nn.InstanceNorm2d(ngf),\n",
    "            nn.ReLU(True)\n",
    "        ]\n",
    "\n",
    "        # Downsampling\n",
    "        in_features = ngf\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "\n",
    "        # Residual blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2,\n",
    "                                   padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "\n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(ngf, output_nc, kernel_size=7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, padding=1)\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "##############################\n",
    "#          MODELS            #\n",
    "##############################\n",
    "\n",
    "netG_A2B = Generator(input_nc, output_nc).to(device)\n",
    "netG_B2A = Generator(output_nc, input_nc).to(device)\n",
    "netD_A = Discriminator(input_nc).to(device)\n",
    "netD_B = Discriminator(output_nc).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnalignedDataset(Dataset):\n",
    "    def __init__(self, root_A, root_B, transform=None):\n",
    "        self.transform = transform\n",
    "        self.files_A = sorted([os.path.join(root_A, f) for f in os.listdir(root_A) if os.path.isfile(os.path.join(root_A, f))])\n",
    "        self.files_B = sorted([os.path.join(root_B, f) for f in os.listdir(root_B) if os.path.isfile(os.path.join(root_B, f))])\n",
    "        self.length_A = len(self.files_A)\n",
    "        self.length_B = len(self.files_B)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_A = Image.open(self.files_A[index % self.length_A]).convert('RGB')\n",
    "        img_B = Image.open(self.files_B[index % self.length_B]).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img_A = self.transform(img_A)\n",
    "            img_B = self.transform(img_B)\n",
    "\n",
    "        return {'A': img_A, 'B': img_B}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(self.length_A, self.length_B)\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(int(size * 1.12), transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.RandomCrop(size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data_folder = \"/home/johntoro/code/GAN/data/\"\n",
    "path_A = data_folder + \"maps/trainA\"\n",
    "path_B = data_folder + \"maps/trainB\"\n",
    "dataset = UnalignedDataset(root_A=path_A, root_B=path_B, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize optimizers\n",
    "optimizer_G = optim.Adam(\n",
    "    itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
    "    lr=lr, betas=(0.5, 0.999)\n",
    ")\n",
    "optimizer_D_A = optim.Adam(netD_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(netD_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "Epoch [1/200] Batch 0/1096 Loss_D: 1.281421422958374, Loss_G: 72.14110565185547\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "Epoch [1/200] Batch 100/1096 Loss_D: 0.4722054600715637, Loss_G: 21.91952133178711\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n",
      "torch.Size([1, 3, 256, 256]) torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#           TRAINING         #\n",
    "##############################\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        real_A = data['A'].to(device)\n",
    "        real_B = data['B'].to(device)\n",
    "        \n",
    "        print(real_A.shape, real_B.shape)\n",
    "\n",
    "        # Generators\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B) * lambda_cyc * lambda_id\n",
    "\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A) * lambda_cyc * lambda_id\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake = netD_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, torch.ones_like(pred_fake).to(device))\n",
    "\n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, torch.ones_like(pred_fake).to(device))\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * lambda_cyc\n",
    "\n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * lambda_cyc\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Discriminator A\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        pred_real = netD_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real).to(device))\n",
    "\n",
    "        pred_fake = netD_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake).to(device))\n",
    "\n",
    "        loss_D_A = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "\n",
    "        # Discriminator B\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        pred_real = netD_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, torch.ones_like(pred_real).to(device))\n",
    "\n",
    "        pred_fake = netD_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, torch.zeros_like(pred_fake).to(device))\n",
    "\n",
    "        loss_D_B = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        # Print log info\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}] Batch {i}/{len(dataloader)} '\n",
    "                  f'Loss_D: {loss_D_A + loss_D_B}, Loss_G: {loss_G}')\n",
    "\n",
    "    # Update learning rates\n",
    "    if epoch > decay_epoch:\n",
    "        lr -= lr / (num_epochs - decay_epoch)\n",
    "        for param_group in optimizer_G.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        for param_group in optimizer_D_A.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        for param_group in optimizer_D_B.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
